{"test_cases_lookup_map": {"{\"actual_output\": \"RAG systems offer improved accuracy by retrieving relevant context, help reduce hallucinations, and allow access to current information from external knowledge bases.\", \"context\": null, \"expected_output\": \"RAG systems provide several benefits including improved accuracy through context retrieval, reduced hallucinations, and the ability to access up-to-date information from external sources.\", \"hyperparameters\": null, \"input\": \"What are the benefits of using RAG systems?\", \"retrieval_context\": [\"Key benefits include improved accuracy through context retrieval, reduced hallucinations, and access to up-to-date information.\", \"RAG (Retrieval-Augmented Generation) systems combine the power of large language models with external knowledge retrieval.\", \"RAG systems can access external knowledge bases, databases, and documents to provide more accurate responses.\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Faithfulness", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because there are no contradictions, indicating a perfect alignment between the actual output and the retrieval context. Great job maintaining accuracy and consistency!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0, "verboseLogs": "Truths (limit=None):\n[\n    \"RAG systems combine large language models with external knowledge retrieval.\",\n    \"RAG systems improve accuracy through context retrieval.\",\n    \"RAG systems reduce hallucinations.\",\n    \"RAG systems provide access to up-to-date information.\",\n    \"RAG systems can access external knowledge bases.\",\n    \"RAG systems can access databases.\",\n    \"RAG systems can access documents to provide more accurate responses.\"\n] \n \nClaims:\n[\n    \"RAG systems offer improved accuracy by retrieving relevant context.\",\n    \"RAG systems help reduce hallucinations.\",\n    \"RAG systems allow access to current information from external knowledge bases.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}, "{\"actual_output\": \"RAG retrieves external context during inference, while fine-tuning updates the model's weights during training. RAG is more flexible for dynamic information.\", \"context\": null, \"expected_output\": \"RAG retrieves external context at inference time while fine-tuning updates model weights during training. RAG is more flexible for dynamic information while fine-tuning requires retraining for new data.\", \"hyperparameters\": null, \"input\": \"What is the difference between RAG and fine-tuning?\", \"retrieval_context\": [\"Fine-tuning updates the model's weights during training on specific data.\", \"RAG and fine-tuning are two different approaches to improving LLM performance.\", \"RAG is more flexible for dynamic information while fine-tuning requires retraining.\", \"RAG retrieves external context at inference time without changing model weights.\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Faithfulness", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because there are no contradictions, indicating a perfect alignment between the actual output and the retrieval context. Great job maintaining accuracy and consistency!", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0, "verboseLogs": "Truths (limit=None):\n[\n    \"RAG and fine-tuning are two different approaches to improving LLM performance.\",\n    \"RAG retrieves external context at inference time without changing model weights.\",\n    \"Fine-tuning updates the model's weights during training on specific data.\",\n    \"RAG is more flexible for dynamic information while fine-tuning requires retraining.\"\n] \n \nClaims:\n[\n    \"RAG retrieves external context during inference.\",\n    \"Fine-tuning updates the model's weights during training.\",\n    \"RAG is more flexible for dynamic information.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}, "{\"actual_output\": \"Vector similarity converts text to numerical vectors and finds the most similar ones using distance metrics such as cosine similarity.\", \"context\": null, \"expected_output\": \"Vector similarity in RAG works by converting text into numerical vectors and finding the most similar vectors using distance metrics like cosine similarity.\", \"hyperparameters\": null, \"input\": \"How does vector similarity work in RAG?\", \"retrieval_context\": [\"Similarity is calculated using distance metrics like cosine similarity or Euclidean distance.\", \"Text is converted into numerical vectors using embedding models.\", \"The most similar vectors are retrieved as relevant context.\", \"Vector similarity is a core component of RAG systems.\"]}": {"cached_metrics_data": [{"metric_data": {"name": "Faithfulness", "threshold": 0.7, "success": false, "score": 0.6666666666666666, "reason": "The score is 0.67 because the actual output incorrectly attributes the conversion of text to numerical vectors to vector similarity, whereas the retrieval context clarifies that this process is achieved through embedding models.", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0, "verboseLogs": "Truths (limit=None):\n[\n    \"Vector similarity is a core component of RAG systems.\",\n    \"Text is converted into numerical vectors using embedding models.\",\n    \"Similarity is calculated using distance metrics like cosine similarity or Euclidean distance.\",\n    \"The most similar vectors are retrieved as relevant context.\"\n] \n \nClaims:\n[\n    \"Vector similarity converts text to numerical vectors.\",\n    \"Vector similarity finds the most similar numerical vectors using distance metrics.\",\n    \"Cosine similarity is a type of distance metric used in vector similarity.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"no\",\n        \"reason\": \"The claim states that vector similarity converts text to numerical vectors, but the retrieval context specifies that text is converted into numerical vectors using embedding models, not vector similarity.\"\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    },\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}}}